{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7d62d978-2175-406f-9f4b-ed0069228e35",
   "metadata": {},
   "source": [
    "![Название изображения](poster_event_1930847.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44448a8-c8f9-466c-85e7-678e574a1127",
   "metadata": {},
   "source": [
    "<p>Мне сказали, что у вас любят шутки :-)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c9047a-8725-439c-adf8-79bbfb63968d",
   "metadata": {},
   "source": [
    "## Контекст"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fc45ae-219b-4dd0-8705-780715945a4e",
   "metadata": {},
   "source": [
    "Вы работаете с покерной платформой, на которой существует несколько типов разметок игроков:\n",
    "<ol>\n",
    "    <li>Автоматические разметки:</li>\n",
    "    <ul>\n",
    "        <li>Запускаются ежедневно через Airflow DAG.</li>\n",
    "        <li>Игроки получают запись в таблице, если попадают в разметку, и не получают, если не попадают.</li>\n",
    "    </ul>\n",
    "    <li>Ручные разметки:</li>\n",
    "    <ul>\n",
    "        <li>Формируются операторами вручную: при попадании добавляется новая строка в таблицу, если игрок больше не должен там быть - статус меняется на амнистирован</li>\n",
    "        <li>Данные хранятся в файлах, обработка которых также выполняется через Airflow DAG.</li>\n",
    "    </ul>\n",
    "</ol>\n",
    "<p>Примерный объем записей 100 тысяч по разметке в день.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c0e3453-141b-4133-8c33-16aad1a5f396",
   "metadata": {},
   "source": [
    "## Проблема\n",
    "<p>Разметки создавались разными командами в разное время и имеют различные форматы.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac712ce6-a490-4121-a952-e9e48c03e596",
   "metadata": {},
   "source": [
    "## Задача \n",
    "<p>Разработать архитектуру сводной таблицы, объединяющей разметки в единую структуру.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9458c09f-07f5-4ce1-aaef-5c52d4f8f1d7",
   "metadata": {},
   "source": [
    "## Цели\n",
    "<ol>\n",
    "    <li>Одним простым запросом понимать состояние игрока на конкретный момент времени - в каких разметках у него метка 1</li>\n",
    "    <li>Хранить историю игрока: когда попал в разметку, когда перестал попадать, когда попал снова</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cdca5f1-cf2e-485e-86ba-257b587bf2e1",
   "metadata": {},
   "source": [
    "## Подход к решению проблемы и достижению целей\n",
    "\n",
    "<p>Исходя из 1 цели, мы можем предположить, что нужен запрос вида\n",
    "<pre><code>\n",
    "SELECT * FROM player_annotations pa WHERE pa.Target = 1\n",
    "</code></pre>\n",
    "</p>\n",
    "<p>Либо, если нам нужен конкретный игрок</p>\n",
    "<pre><code>\n",
    "SELECT * FROM player_annotations pa WHERE pa.Target = 1 AND pa.PlayerID = 25\n",
    "</code></pre>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6367e4fd-efda-40a3-ac5d-92d795aff9b9",
   "metadata": {},
   "source": [
    "<p>Здесь есть нюанс, что метка - по сути означает, что у игрока нет записи Detected от прошлого числа из автоматической разметки или нет записей в ручной разметке. В нашем случае проще всего будет использовать логику пустой даты. <br>\n",
    "<b>Пример 1:</b> игрок получил автоматический Detected 10.02.2025 и мы записали это в конечную сводную таблицу с пустой датой окончания. В день, когда автоматическая система не присвоила ему Detected, мы ставим дату окончания. <br>\n",
    "<b>Пример 2:</b> игрока записали в файл 10.02.2025 и мы спарсили это в конечную таблицу с пустой датой окончания. В день, когда появилась запись Amnisted, мы ставим дату окончания. <br>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f20f06-a759-44dd-9e5f-2008f03193d2",
   "metadata": {},
   "source": [
    "<p>Соответственно, SQL запрос изменится:\n",
    "<pre><code>\n",
    "SELECT * FROM player_annotations pa WHERE pa.ValidUntil IS NULL AND pa.PlayerID = 25\n",
    "</code></pre>\n",
    "</p>\n",
    "С помощью такой логики, мы получим всего 2 возможных строки: <br>\n",
    "<ul>\n",
    "    <li>для автоматической разметки</li>\n",
    "    <li>для ручной разметки</li>\n",
    "</ul>\n",
    "А по запросу\n",
    "<pre><code>\n",
    "SELECT * FROM player_annotations pa WHERE pa.PlayerID = 25\n",
    "</code></pre>\n",
    "Мы получим всю историю игрока, тем самым мы достигнем второй цели"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca774a7-0184-4fe3-ab40-50c92d242e6c",
   "metadata": {},
   "source": [
    "## Структура сводной таблицы\n",
    "<p>\n",
    "    <pre><code>\n",
    "CREATE TABLE player_annotations (\n",
    "    ID UInt64 DEFAULT rowNumber() OVER (),\n",
    "    PlayerID UInt64,                \n",
    "    DetectedType Enum('Automatic' = 1, 'Manual' = 2),  \n",
    "    ValidFrom DateTime,              \n",
    "    ValidUntil Nullable(DateTime),  \n",
    "    CreatedBy String,              \n",
    "    PRIMARY KEY (PlayerID, ID)  \n",
    ") ENGINE = MergeTree()\n",
    "ORDER BY (PlayerID, ID);\n",
    "\n",
    "\n",
    "</code></pre>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000692a5-6d0c-4056-8880-812432a21aa0",
   "metadata": {},
   "source": [
    "<p>Зачем нужно поле <b>CreatedBy?</b><br>\n",
    "Исходя из своего опыта, могу сказать, что это поле нужно для дальнейшей аналитики и раздачи кнутов и пряников. Когда нам потребуется понять кто из операторов выдал Detected или Amnisted, количество и т.д. С автоматической всё понятно.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43cbc2f-c168-40ef-ae08-e0d9788f472b",
   "metadata": {},
   "source": [
    "## Логика добавления записей"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbde0e7d-ed0b-4827-9c61-3166f18b34d0",
   "metadata": {},
   "source": [
    "![изображения](diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0311c4f-9084-4b44-ae59-a0c39849fb7d",
   "metadata": {},
   "source": [
    "<p>Как видно из графа, у нас будет корень - выгрузка из сводной таблицы записей с пустой датой и 2 ветви Auto и Manual. В Airflow мы можем пойти двумя путями:\n",
    "<ul>\n",
    "    <li>распараллелить эти две таски</li>\n",
    "    <li>выполнять их друг за другом</li>\n",
    "</ul>\n",
    "Из ТЗ могу предположить, что эти две разметки не влияют друг на другом, а значит нам подойдёт любой вариант. <br>\n",
    "Но я выберу вариант с параллельным выполнением, так как один из источников может быть недоступен. К примеру, у нас отвалилась БД или сетевой диск с файлами.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a6ebb69-2d5d-4bee-a36a-7270b01fbfd5",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'airflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mairflow\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DAG\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mairflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moperators\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PythonOperator\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'airflow'"
     ]
    }
   ],
   "source": [
    "from airflow import DAG\n",
    "from airflow.operators.python import PythonOperator\n",
    "import pandas as pd\n",
    "import clickhouse_connect\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "CLICKHOUSE_HOST = 'Хост'\n",
    "CLICKHOUSE_DB = 'БД'\n",
    "\n",
    "\n",
    "def fetch_null_valid_until(**kwargs):\n",
    "    \"\"\"\n",
    "    Извлекает записи из таблицы player_annotations, \n",
    "    где поле ValidUntil имеет значение NULL.\n",
    "    Данные загружаются в DataFrame и передаются \n",
    "    в XCom для последующего использования.\n",
    "    Параметры:\n",
    "        kwargs (dict): Словарь параметров Airflow, содержащий контекст выполнения DAG.\n",
    "    Возвращает:\n",
    "        None: Данные сохраняются в XCom с ключом 'player_data'.\n",
    "    \"\"\"\n",
    "    client = clickhouse_connect.get_client(host=CLICKHOUSE_HOST, database=CLICKHOUSE_DB)\n",
    "\n",
    "    #Здесь я специально выбираю конкретные поля, чтобы получить ожидаемый результат\n",
    "    #так как структура таблицы может измениться (добавят новое поле)\n",
    "    #защита от дурака =)\n",
    "    query = \"\"\"\n",
    "        SELECT pa.ID, pa.PlayerID, pa.DetectedType, pa.ValidFromDateTime, \n",
    "               pa.ValidUntil, pa.CreatedBy\n",
    "        FROM player_annotations pa \n",
    "        WHERE pa.ValidUntil IS NULL\n",
    "    \"\"\"\n",
    "    \n",
    "    result = client.query(query)\n",
    "    df = pd.DataFrame(result.result_rows, columns=[col[0] for col in result.result_columns])\n",
    "\n",
    "    #записываю в словарь параметров, чтобы перекидывать между функциями\n",
    "    kwargs['TillDetected'].xcom_push(key='player_data', value=df.to_dict())\n",
    "\n",
    "\n",
    "def auto_annotation(**kwargs):\n",
    "    \"\"\"\n",
    "    Функция обработки автоматической разметки. \n",
    "    Записывает новых игроков с пометкой Detected и обновляет записи для старых.\n",
    "    По PEP8 её нужно разбить на 2 отдельные функции, но в рамках тестового мне это делать лень =)\n",
    "    Параметры:\n",
    "        kwargs (dict): Словарь параметров Airflow, содержащий контекст выполнения DAG.\n",
    "    Возвращает:\n",
    "        None: Данные сохраняются в XCom с ключом 'player_data'.\n",
    "    \"\"\"\n",
    "    ti = kwargs['TillDetected']\n",
    "    ds = kwargs['ds']  # Здесь возможно использовать {ds}, вместо kwargs['ds']\n",
    "    \n",
    "    df = pd.DataFrame.from_dict(ti.xcom_pull(task_ids='fetch_null_valid_until', key='player_data'))\n",
    "    \n",
    "    client = clickhouse_connect.get_client(host=CLICKHOUSE_HOST, database=CLICKHOUSE_DB)\n",
    "    \n",
    "    # Предположим, что таблица которая автоматический размечает игроков называется logs\n",
    "    query_logs = f\"\"\"\n",
    "        SELECT l.PlayerID, l.DetectedAt \n",
    "        FROM logs l \n",
    "        WHERE l.DetectedAt = '{ds}'\n",
    "    \"\"\"\n",
    "    logs_df = client.query_df(query_logs)\n",
    "    \n",
    "    # Проверяем, каких PlayerID нет в df, но есть в logs\n",
    "    missing_players = logs_df[~logs_df['PlayerID'].isin(df['PlayerID'])]\n",
    "    \n",
    "    #Здесь сформируется запись вида \"5 Auto 2025.02.19 None Auto\"\n",
    "    #Т.е. при выгрузке SELECT * FROM player_annotations pa WHERE pa.PlayerID = 5\n",
    "    #AND pa.ValidUntil IS NULL\n",
    "    #мы получим именно эту запись или вместе с ручной\n",
    "    new_records = [\n",
    "        (uuid.uuid4().int, row['PlayerID'], \"Auto\", ds, None, \"Auto\") \n",
    "        for _, row in missing_players.iterrows()\n",
    "    ]\n",
    "    \n",
    "    if new_records:\n",
    "        client.insert(\n",
    "            'player_annotations',\n",
    "            new_records,\n",
    "            column_names=['ID', 'PlayerID', 'DetectedType', 'ValidFrom', 'ValidUntil', 'Status']\n",
    "        )\n",
    "    \n",
    "    # Проверяем, кого из PlayerID в df нет в logs\n",
    "    missing_in_logs = df[~df['PlayerID'].isin(logs_df['PlayerID'])]\n",
    "\n",
    "    #А здесь, мы завершаем действие записи. Т.е. у нас была запись вида \"5 Auto 2025.02.19 None Auto\"\n",
    "    #Теперь мы делаем её \"5 Auto 2025.02.19 2025.02.25 Auto\", что будет означать игрок пробыл в авто-разметке с 19 по 25 февраля\n",
    "    if not missing_in_logs.empty:\n",
    "        for player_id in missing_in_logs['PlayerID']:\n",
    "            update_query = f\"\"\"\n",
    "                ALTER TABLE player_annotations pa\n",
    "                UPDATE pa.ValidUntil = '{ds}' \n",
    "                WHERE pa.PlayerID = '{player_id}' AND pa.ValidUntil IS NULL AND pa.DetectedType = 'Auto'\n",
    "            \"\"\"\n",
    "            client.command(update_query)\n",
    "\n",
    "            \n",
    "def manual_annotation(**kwargs):\n",
    "    \"\"\"\n",
    "    Функция обработки ручной аннотации.\n",
    "    Записывает новых игроков с пометкой Detected и обновляет записи для старых добавленных через файлы.\n",
    "    Параметры:\n",
    "        kwargs (dict): Словарь параметров Airflow, содержащий контекст выполнения DAG.\n",
    "    Возвращает:\n",
    "        None: Данные сохраняются в XCom с ключом 'player_data'.\n",
    "   \n",
    "    \"\"\"\n",
    "    ti = kwargs['TillDetected']\n",
    "    ds = kwargs['ds'] \n",
    "    tasks_folder = \"Tasks\"\n",
    "    \n",
    "    all_data = []\n",
    "    \n",
    "    #Считываем все файлы в папке\n",
    "    for filename in os.listdir(tasks_folder):\n",
    "        filepath = os.path.join(tasks_folder, filename)\n",
    "        if os.path.isfile(filepath) and filename.endswith(\".csv\"):\n",
    "            df = pd.read_csv(filepath)\n",
    "            \n",
    "            # Защита от дурака. Оператор мог добавить новый столбец с комментариями\n",
    "            # и мы можем не получить ожидаемого результата\n",
    "            required_columns = {'DetectedAt', 'PlayerID', 'Status'}\n",
    "            if not required_columns.issubset(df.columns):\n",
    "                continue\n",
    "            \n",
    "            # Любая запись где есть хоть один пропуск не имеет смысла\n",
    "            # С пропущенной датой - непонятно когда начинать/заканчивать\n",
    "            # С пропущенным PlayerID - непонятно кому выдаём\n",
    "            # С пропущенным Status - непонятно, наказываем или амнистируем\n",
    "            df = df.dropna(subset=required_columns)\n",
    "            \n",
    "            # Добавляем имя файла в колонку \n",
    "            #(вообще тут должно быть поле, которое отвечает за оператора, но пока просто файл)\n",
    "            df['FileName'] = filename\n",
    "            \n",
    "            all_data.append(df)\n",
    "    \n",
    "    if not all_data:\n",
    "        return\n",
    "    \n",
    "    combined_df = pd.concat(all_data, ignore_index=True)\n",
    "\n",
    "    #Мы предполагаем, что записей \"задним числом\" быть не может и поэтому отбираем только сегодняшние записи\n",
    "    filtered_df = combined_df[combined_df['DetectedAt'] == ds]\n",
    "    \n",
    "    client = clickhouse_connect.get_client(host=CLICKHOUSE_HOST, database=CLICKHOUSE_DB)\n",
    "    \n",
    "    #Здесь сформируется запись вида \"5 Manual 2025.02.19 None Petrenko.csv\"\n",
    "    #Т.е. при выгрузке SELECT * FROM player_annotations pa WHERE pa.PlayerID = 5\n",
    "    #AND pa.ValidUntil IS NULL\n",
    "    #мы получим именно эту запись или вместе с автоматической\n",
    "    detected_records = [\n",
    "        (row['PlayerID'], \"Manual\", ds, None, row['FileName'])\n",
    "        for _, row in filtered_df[filtered_df['Status'] == \"Detected\"].iterrows()\n",
    "    ]\n",
    "    \n",
    "    if detected_records:\n",
    "        client.insert(\n",
    "            'player_annotations',\n",
    "            detected_records,\n",
    "            column_names=['PlayerID', 'DetectedType', 'ValidFrom', 'ValidUntil', 'CreatedBy']\n",
    "        )\n",
    "    \n",
    "    # А здесь, мы завершаем действие ручной записи\n",
    "    amnisted_players = filtered_df[filtered_df['Status'] == \"Amnisted\"]['PlayerID'].tolist()\n",
    "    \n",
    "    if amnisted_players:\n",
    "        for player_id in amnisted_players:\n",
    "            update_query = f\"\"\"\n",
    "                ALTER TABLE player_annotations pa \n",
    "                UPDATE pa.ValidUntil = '{ds}' \n",
    "                WHERE pa.PlayerID = '{player_id}' AND pa.ValidUntil IS NULL AND pa.DetectedType = 'Manual'\n",
    "            \"\"\"\n",
    "            client.command(update_query)\n",
    "\n",
    "\n",
    "# Определяем DAG\n",
    "default_args = {\n",
    "    'owner': 'Deeplay',\n",
    "    'start_date': datetime(2025, 1, 1),\n",
    "    'retries': 5, #делаем перезапуск 5 раз с интервалом 30 минут на случай перебоев с сетью\n",
    "    'retry_delay': timedelta(minutes=30), \n",
    "}\n",
    "\n",
    "dag = DAG(\n",
    "    'clickhouse_annotation_pipeline',\n",
    "    default_args=default_args,\n",
    "    schedule_interval='0 1 * * *',  #запускаем каждый день в час ночи (+3 UTC если на сервере старая версия Airflow)\n",
    "    catchup=False #Тут возможно True, в зависимости от того когда мы запустим и хотим ли мы добрать историю \n",
    ")\n",
    "\n",
    "# Задача: выгрузка данных из ClickHouse\n",
    "fetch_data = PythonOperator(\n",
    "    task_id='fetch_null_valid_until',\n",
    "    python_callable=fetch_null_valid_until,\n",
    "    provide_context=True,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# Задачи аннотации\n",
    "auto_annotate = PythonOperator(\n",
    "    task_id='auto_annotation',\n",
    "    python_callable=auto_annotation,\n",
    "    provide_context=True,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "manual_annotate = PythonOperator(\n",
    "    task_id='manual_annotation',\n",
    "    python_callable=manual_annotation,\n",
    "    provide_context=True,\n",
    "    dag=dag\n",
    ")\n",
    "\n",
    "# Очередность выполнения\n",
    "# Мы будем ждать выполнения fetch_data, а вот auto и manual будут выполняться параллельно\n",
    "# что гарантирует в случае падения одного из источников, что второй продолжит работу\n",
    "fetch_data >> [auto_annotate, manual_annotate]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1af7e25-8f8a-4317-95c1-18c0643441d3",
   "metadata": {},
   "source": [
    "<p>\n",
    "    В целом тут ещё много можно добавить для поиска исключений или различной логики (к примеру, что Auto и Manual влияют друг на друга). <br>\n",
    "    Но тут нужно уже знать контекст задачи. <br>\n",
    "    Делал на личном компьютере, естественно у меня нет airflow и проверить скрипт не смог. А корпоративный Airflow имеет немного другой синтаксис, что было бы неудобно для вас. <br>\n",
    "    Вместо Pandas можно использовать Polars, Spark или другие.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4e4231-1342-4667-b0d4-f8f1d7d2ad7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
